{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import tokenization\n",
    "from modeling import BertConfig, BertForSequenceClassification\n",
    "from optimization import BERTAdam\n",
    "from processor import (Semeval_NLI_B_Processor, Semeval_NLI_M_Processor,\n",
    "                       Semeval_QA_B_Processor, Semeval_QA_M_Processor,\n",
    "                       Semeval_single_Processor, Sentihood_NLI_B_Processor,\n",
    "                       Sentihood_NLI_M_Processor, Sentihood_QA_B_Processor,\n",
    "                       Sentihood_QA_M_Processor, Sentihood_single_Processor,\n",
    "                       Covid_NLI_B_Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(tqdm(examples)):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "        if tokens_b:\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        else:\n",
    "            # Account for [CLS] and [SEP] with \"- 2\"\n",
    "            if len(tokens_a) > max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "        # The convention in BERT is:\n",
    "        # (a) For sequence pairs:\n",
    "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "        #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "        # (b) For single sequences:\n",
    "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "        #  type_ids: 0   0   0   0  0     0 0\n",
    "        #\n",
    "        # Where \"type_ids\" are used to indicate whether this is the first\n",
    "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "        # embedding vector (and position vector). This is not *strictly* necessary\n",
    "        # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "        # it easier for the model to learn the concept of sequences.\n",
    "        #\n",
    "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "        # the entire model is fine-tuned.\n",
    "        tokens = []\n",
    "        segment_ids = []\n",
    "        tokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        for token in tokens_a:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        if tokens_b:\n",
    "            for token in tokens_b:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(1)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label_map[example.label]\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        label_id=label_id))\n",
    "    return features\n",
    "\n",
    "\n",
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg:\n",
    "    def __init__(self):\n",
    "        self.task_name = 'Covid_NLI_B'\n",
    "        self.data_dir = 'data/covid/bert-pair'\n",
    "        self.vocab_file = 'uncased_L-12_H-768_A-12/vocab.txt '\n",
    "        self.bert_config_file = 'uncased_L-12_H-768_A-12/bert_config.json '\n",
    "        self.init_checkpoint = 'uncased_L-12_H-768_A-12/pytorch_model.bin '\n",
    "        self.eval_test = True\n",
    "        self.do_lower_case = True\n",
    "        self.max_seq_length = 512 \n",
    "        self.no_cuda = False\n",
    "        self.train_batch_size = 24 \n",
    "        self.learning_rate = 2e-5 \n",
    "        self.warmup_proportion = 0.1\n",
    "        self.num_train_epochs = 0 \n",
    "        self.eval_batch_size = 8\n",
    "        self.accumulate_gradients = 1\n",
    "        self.output_dir = 'results/covid/NLI_B_EVAL_NB'\n",
    "        self.seed = 42\n",
    "        self.local_rank = -1\n",
    "        self.init_eval_checkpoint = 'results/covid/NLI_B_savemodel/model_ep_1.bin'\n",
    "args = Arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/11/2021 13:57:17 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n"
     ]
    }
   ],
   "source": [
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(args.local_rank != -1))\n",
    "\n",
    "if args.accumulate_gradients < 1:\n",
    "    raise ValueError(\"Invalid accumulate_gradients parameter: {}, should be >= 1\".format(\n",
    "                        args.accumulate_gradients))\n",
    "\n",
    "args.train_batch_size = int(args.train_batch_size / args.accumulate_gradients)\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "bert_config = BertConfig.from_json_file(args.bert_config_file)\n",
    "\n",
    "if args.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length {} because the BERT model was only trained up to sequence length {}\".format(\n",
    "        args.max_seq_length, bert_config.max_position_embeddings))\n",
    "\n",
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir):\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# prepare dataloaders\n",
    "processors = {\n",
    "    \"Covid_NLI_B\":Covid_NLI_B_Processor,\n",
    "    \"sentihood_single\":Sentihood_single_Processor,\n",
    "    \"sentihood_NLI_M\":Sentihood_NLI_M_Processor,\n",
    "    \"sentihood_QA_M\":Sentihood_QA_M_Processor,\n",
    "    \"sentihood_NLI_B\":Sentihood_NLI_B_Processor,\n",
    "    \"sentihood_QA_B\":Sentihood_QA_B_Processor,\n",
    "    \"semeval_single\":Semeval_single_Processor,\n",
    "    \"semeval_NLI_M\":Semeval_NLI_M_Processor,\n",
    "    \"semeval_QA_M\":Semeval_QA_M_Processor,\n",
    "    \"semeval_NLI_B\":Semeval_NLI_B_Processor,\n",
    "    \"semeval_QA_B\":Semeval_QA_B_Processor,\n",
    "}\n",
    "\n",
    "processor = processors[args.task_name]()\n",
    "label_list = processor.get_labels()\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "vocab_file=args.vocab_file, do_lower_case=args.do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "guid= train-0\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "1000\n",
      "guid= train-1000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "2000\n",
      "guid= train-2000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "3000\n",
      "guid= train-3000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "4000\n",
      "guid= train-4000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "5000\n",
      "guid= train-5000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "6000\n",
      "guid= train-6000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "7000\n",
      "guid= train-7000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "8000\n",
      "guid= train-8000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "9000\n",
      "guid= train-9000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "10000\n",
      "guid= train-10000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "11000\n",
      "guid= train-11000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "12000\n",
      "guid= train-12000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "13000\n",
      "guid= train-13000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "14000\n",
      "guid= train-14000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "15000\n",
      "guid= train-15000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "16000\n",
      "guid= train-16000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "17000\n",
      "guid= train-17000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "18000\n",
      "guid= train-18000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "19000\n",
      "guid= train-19000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "20000\n",
      "guid= train-20000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "21000\n",
      "guid= train-21000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "22000\n",
      "guid= train-22000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "23000\n",
      "guid= train-23000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "24000\n",
      "guid= train-24000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "25000\n",
      "guid= train-25000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "26000\n",
      "guid= train-26000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "27000\n",
      "guid= train-27000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "28000\n",
      "guid= train-28000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "29000\n",
      "guid= train-29000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "30000\n",
      "guid= train-30000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "31000\n",
      "guid= train-31000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "32000\n",
      "guid= train-32000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "33000\n",
      "guid= train-33000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "34000\n",
      "guid= train-34000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "35000\n",
      "guid= train-35000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "36000\n",
      "guid= train-36000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "37000\n",
      "guid= train-37000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "38000\n",
      "guid= train-38000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "39000\n",
      "guid= train-39000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "40000\n",
      "guid= train-40000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "41000\n",
      "guid= train-41000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "42000\n",
      "guid= train-42000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "43000\n",
      "guid= train-43000\n",
      "text_a= unrelated - racism\n",
      "label= 0\n",
      "44000\n",
      "guid= train-44000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "45000\n",
      "guid= train-45000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "46000\n",
      "guid= train-46000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "47000\n",
      "guid= train-47000\n",
      "text_a= unrelated - racism\n",
      "label= 0\n",
      "48000\n",
      "guid= train-48000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "49000\n",
      "guid= train-49000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "50000\n",
      "guid= train-50000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "51000\n",
      "guid= train-51000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "52000\n",
      "guid= train-52000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "53000\n",
      "guid= train-53000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "54000\n",
      "guid= train-54000\n",
      "text_a= unrelated - situation\n",
      "label= 0\n",
      "55000\n",
      "guid= train-55000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "56000\n",
      "guid= train-56000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "57000\n",
      "guid= train-57000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "58000\n",
      "guid= train-58000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "59000\n",
      "guid= train-59000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "60000\n",
      "guid= train-60000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "61000\n",
      "guid= train-61000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "62000\n",
      "guid= train-62000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "63000\n",
      "guid= train-63000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "64000\n",
      "guid= train-64000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "65000\n",
      "guid= train-65000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "66000\n",
      "guid= train-66000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "67000\n",
      "guid= train-67000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "68000\n",
      "guid= train-68000\n",
      "text_a= unrelated - politics\n",
      "label= 0\n",
      "69000\n",
      "guid= train-69000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "70000\n",
      "guid= train-70000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "71000\n",
      "guid= train-71000\n",
      "text_a= unrelated - racism\n",
      "label= 0\n",
      "72000\n",
      "guid= train-72000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "73000\n",
      "guid= train-73000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "74000\n",
      "guid= train-74000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "75000\n",
      "guid= train-75000\n",
      "text_a= unrelated - racism\n",
      "label= 0\n",
      "76000\n",
      "guid= train-76000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "77000\n",
      "guid= train-77000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "78000\n",
      "guid= train-78000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "79000\n",
      "guid= train-79000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "80000\n",
      "guid= train-80000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "81000\n",
      "guid= train-81000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "82000\n",
      "guid= train-82000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "83000\n",
      "guid= train-83000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "84000\n",
      "guid= train-84000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "85000\n",
      "guid= train-85000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "86000\n",
      "guid= train-86000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "87000\n",
      "guid= train-87000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "88000\n",
      "guid= train-88000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "89000\n",
      "guid= train-89000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "90000\n",
      "guid= train-90000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "91000\n",
      "guid= train-91000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "92000\n",
      "guid= train-92000\n",
      "text_a= unrelated - politics\n",
      "label= 0\n",
      "93000\n",
      "guid= train-93000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "94000\n",
      "guid= train-94000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "95000\n",
      "guid= train-95000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "96000\n",
      "guid= train-96000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "97000\n",
      "guid= train-97000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "98000\n",
      "guid= train-98000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "99000\n",
      "guid= train-99000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "100000\n",
      "guid= train-100000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "101000\n",
      "guid= train-101000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "102000\n",
      "guid= train-102000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "103000\n",
      "guid= train-103000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "104000\n",
      "guid= train-104000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "105000\n",
      "guid= train-105000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "106000\n",
      "guid= train-106000\n",
      "text_a= unrelated - situation\n",
      "label= 0\n",
      "107000\n",
      "guid= train-107000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "108000\n",
      "guid= train-108000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "109000\n",
      "guid= train-109000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "110000\n",
      "guid= train-110000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "111000\n",
      "guid= train-111000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "112000\n",
      "guid= train-112000\n",
      "text_a= unrelated - politics\n",
      "label= 0\n",
      "113000\n",
      "guid= train-113000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "114000\n",
      "guid= train-114000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "115000\n",
      "guid= train-115000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "116000\n",
      "guid= train-116000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "117000\n",
      "guid= train-117000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "118000\n",
      "guid= train-118000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "119000\n",
      "guid= train-119000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "120000\n",
      "guid= train-120000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "121000\n",
      "guid= train-121000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "122000\n",
      "guid= train-122000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "123000\n",
      "guid= train-123000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "124000\n",
      "guid= train-124000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "125000\n",
      "guid= train-125000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "126000\n",
      "guid= train-126000\n",
      "text_a= unrelated - situation\n",
      "label= 0\n",
      "127000\n",
      "guid= train-127000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "128000\n",
      "guid= train-128000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "129000\n",
      "guid= train-129000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "130000\n",
      "guid= train-130000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "131000\n",
      "guid= train-131000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "132000\n",
      "guid= train-132000\n",
      "text_a= unrelated - politics\n",
      "label= 0\n",
      "133000\n",
      "guid= train-133000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "134000\n",
      "guid= train-134000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "135000\n",
      "guid= train-135000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "136000\n",
      "guid= train-136000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "137000\n",
      "guid= train-137000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "138000\n",
      "guid= train-138000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "139000\n",
      "guid= train-139000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "140000\n",
      "guid= train-140000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "141000\n",
      "guid= train-141000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "142000\n",
      "guid= train-142000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "143000\n",
      "guid= train-143000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "144000\n",
      "guid= train-144000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "145000\n",
      "guid= train-145000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "146000\n",
      "guid= train-146000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "147000\n",
      "guid= train-147000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "148000\n",
      "guid= train-148000\n",
      "text_a= unrelated - politics\n",
      "label= 0\n",
      "149000\n",
      "guid= train-149000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "150000\n",
      "guid= train-150000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "151000\n",
      "guid= train-151000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "152000\n",
      "guid= train-152000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "153000\n",
      "guid= train-153000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "154000\n",
      "guid= train-154000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "155000\n",
      "guid= train-155000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "156000\n",
      "guid= train-156000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "157000\n",
      "guid= train-157000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "158000\n",
      "guid= train-158000\n",
      "text_a= unrelated - situation\n",
      "label= 0\n",
      "159000\n",
      "guid= train-159000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "160000\n",
      "guid= train-160000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "161000\n",
      "guid= train-161000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 161120/161120 [01:47<00:00, 1497.75it/s]\n",
      "12/11/2021 13:59:17 - INFO - __main__ -   ***** Running training *****\n",
      "12/11/2021 13:59:17 - INFO - __main__ -     Num examples = 161120\n",
      "12/11/2021 13:59:17 - INFO - __main__ -     Batch size = 24\n",
      "12/11/2021 13:59:17 - INFO - __main__ -     Num steps = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "guid= test-0\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "1000\n",
      "guid= test-1000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "2000\n",
      "guid= test-2000\n",
      "text_a= unrelated - situation\n",
      "label= 1\n",
      "3000\n",
      "guid= test-3000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "4000\n",
      "guid= test-4000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n",
      "5000\n",
      "guid= test-5000\n",
      "text_a= unrelated - foreign\n",
      "label= 1\n",
      "6000\n",
      "guid= test-6000\n",
      "text_a= unrelated - situation\n",
      "label= 0\n",
      "7000\n",
      "guid= test-7000\n",
      "text_a= unrelated - racism\n",
      "label= 1\n",
      "8000\n",
      "guid= test-8000\n",
      "text_a= unrelated - politics\n",
      "label= 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 8512/8512 [00:05<00:00, 1423.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "train_examples = None\n",
    "num_train_steps = None\n",
    "train_examples = processor.get_train_examples(args.data_dir)\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / args.train_batch_size * args.num_train_epochs)\n",
    "\n",
    "train_features = convert_examples_to_features(\n",
    "    train_examples, label_list, args.max_seq_length, tokenizer)\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
    "logger.info(\"  Num steps = %d\", num_train_steps)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "if args.local_rank == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)\n",
    "\n",
    "# test set\n",
    "test_examples = processor.get_test_examples(args.data_dir)\n",
    "test_features = convert_examples_to_features(\n",
    "test_examples, label_list, args.max_seq_length, tokenizer)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in test_features], dtype=torch.long)\n",
    "\n",
    "test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "test_dataloader = DataLoader(test_data, batch_size=args.eval_batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer\n",
    "model = BertForSequenceClassification(bert_config, len(label_list))\n",
    "if args.init_eval_checkpoint is not None:\n",
    "    model.load_state_dict(torch.load(args.init_eval_checkpoint, map_location='cpu'))\n",
    "elif args.init_checkpoint is not None:\n",
    "    model.bert.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))\n",
    "model.to(device)\n",
    "\n",
    "if args.local_rank != -1:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                      output_device=args.local_rank)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_parameters = [\n",
    "     {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "     {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "     ]\n",
    "\n",
    "optimizer = BERTAdam(optimizer_parameters,\n",
    "                     lr=args.learning_rate,\n",
    "                     warmup=args.warmup_proportion,\n",
    "                     t_total=num_train_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.85171667e-02 9.11482811e-01]\n",
      " [9.92075920e-01 7.92405941e-03]\n",
      " [8.90031457e-01 1.09968565e-01]\n",
      " [9.98793125e-01 1.20683329e-03]\n",
      " [9.92757548e-03 9.90072370e-01]\n",
      " [9.94671762e-01 5.32828923e-03]\n",
      " [9.98390675e-01 1.60935021e-03]\n",
      " [9.99854088e-01 1.45898186e-04]]\n",
      "logits: (0.088,0.911)  Argmaxed:1\n",
      "logits: (0.992,0.007)  Argmaxed:0\n",
      "logits: (0.890,0.109)  Argmaxed:0\n",
      "logits: (0.998,0.001)  Argmaxed:0\n",
      "logits: (0.009,0.990)  Argmaxed:1\n",
      "logits: (0.994,0.005)  Argmaxed:0\n",
      "logits: (0.998,0.001)  Argmaxed:0\n",
      "logits: (0.999,0.000)  Argmaxed:0\n",
      "prediction: [1 0 0 0 1 0 0 0]\n",
      "labels:     [1 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9135faeeb1a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mnb_test_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnb_test_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnb_test_examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss, test_accuracy = 0, 0\n",
    "nb_test_steps, nb_test_examples = 0, 0\n",
    "for input_ids, input_mask, segment_ids, label_ids in test_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tmp_test_loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "    logits = F.softmax(logits, dim=-1)\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = label_ids.to('cpu').numpy()\n",
    "#     print(label_ids)\n",
    "    print(logits)\n",
    "    outputs = np.argmax(logits, axis=1)\n",
    "    \n",
    "    for output_i in range(len(outputs)):\n",
    "#         print(logits)\n",
    "        print(f\"logits: ({str(logits[output_i][0])[:5]},{str(logits[output_i][1])[:5]})  Argmaxed:{outputs[output_i]}\")\n",
    "\n",
    "\n",
    "           \n",
    "    print('prediction:',outputs)\n",
    "    print('labels:    ',label_ids)\n",
    "    break\n",
    "    tmp_test_accuracy=np.sum(outputs == label_ids)\n",
    "\n",
    "    test_loss += tmp_test_loss.mean().item()\n",
    "    test_accuracy += tmp_test_accuracy\n",
    "\n",
    "    nb_test_examples += input_ids.size(0)\n",
    "    nb_test_steps += 1\n",
    "\n",
    "test_loss = test_loss / nb_test_steps\n",
    "test_accuracy = test_accuracy / nb_test_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[8.85171667e-02 9.11482811e-01]\n",
    " [9.92075920e-01 7.92405941e-03]\n",
    " [8.90031457e-01 1.09968565e-01]\n",
    " [9.98793125e-01 1.20683329e-03]\n",
    " [9.92757548e-03 9.90072370e-01]\n",
    " [9.94671762e-01 5.32828923e-03]\n",
    " [9.98390675e-01 1.60935021e-03]\n",
    " [9.99854088e-01 1.45898186e-04]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "8507    0\n",
       "8508    0\n",
       "8509    1\n",
       "8510    0\n",
       "8511    0\n",
       "Name: 1, Length: 8512, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('.\\\\data\\\\covid\\\\bert-pair\\\\test_NLI_B.csv',sep='\\t',header=None)\n",
    "df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "8507    0\n",
       "8508    0\n",
       "8509    0\n",
       "8510    0\n",
       "8511    0\n",
       "Name: 0, Length: 8512, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('.\\\\results\\\\covid\\\\NLI_B_EVAL\\\\test_ep_0.txt',sep=' ',header=None)\n",
    "df_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9339755639097744"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[1]==df_pred[0]).sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>negative - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>positive - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated - economy</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0  1                     2  \\\n",
       "0  1229853968957833216  1  unrelated - politics   \n",
       "1  1229853968957833216  0    neutral - politics   \n",
       "2  1229853968957833216  0   negative - politics   \n",
       "3  1229853968957833216  0   positive - politics   \n",
       "4  1229853968957833216  1   unrelated - economy   \n",
       "\n",
       "                                                   3  pred  \n",
       "0  Self-driving technology + road roller! #CSCEC ...     1  \n",
       "1  Self-driving technology + road roller! #CSCEC ...     0  \n",
       "2  Self-driving technology + road roller! #CSCEC ...     0  \n",
       "3  Self-driving technology + road roller! #CSCEC ...     0  \n",
       "4  Self-driving technology + road roller! #CSCEC ...     1  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pred'] = df_pred[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Self-driving technology + road roller! #CSCEC ...\n",
       "1       Self-driving technology + road roller! #CSCEC ...\n",
       "2       Self-driving technology + road roller! #CSCEC ...\n",
       "3       Self-driving technology + road roller! #CSCEC ...\n",
       "4       Self-driving technology + road roller! #CSCEC ...\n",
       "                              ...                        \n",
       "8507    This very crafty Beijing taxi driver construct...\n",
       "8508    This very crafty Beijing taxi driver construct...\n",
       "8509    This very crafty Beijing taxi driver construct...\n",
       "8510    This very crafty Beijing taxi driver construct...\n",
       "8511    This very crafty Beijing taxi driver construct...\n",
       "Name: 3, Length: 8512, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[0,1,'pred',2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>pred</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive - politics</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1229853968957833216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>unrelated - economy</td>\n",
       "      <td>Self-driving technology + road roller! #CSCEC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>1233983941692076032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive - racism</td>\n",
       "      <td>This very crafty Beijing taxi driver construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>1233983941692076032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>unrelated - overall</td>\n",
       "      <td>This very crafty Beijing taxi driver construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>1233983941692076032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral - overall</td>\n",
       "      <td>This very crafty Beijing taxi driver construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8510</th>\n",
       "      <td>1233983941692076032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative - overall</td>\n",
       "      <td>This very crafty Beijing taxi driver construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8511</th>\n",
       "      <td>1233983941692076032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive - overall</td>\n",
       "      <td>This very crafty Beijing taxi driver construct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0  1  pred                     2  \\\n",
       "0     1229853968957833216  1     1  unrelated - politics   \n",
       "1     1229853968957833216  0     0    neutral - politics   \n",
       "2     1229853968957833216  0     0   negative - politics   \n",
       "3     1229853968957833216  0     0   positive - politics   \n",
       "4     1229853968957833216  1     1   unrelated - economy   \n",
       "...                   ... ..   ...                   ...   \n",
       "8507  1233983941692076032  0     0     positive - racism   \n",
       "8508  1233983941692076032  0     0   unrelated - overall   \n",
       "8509  1233983941692076032  1     0     neutral - overall   \n",
       "8510  1233983941692076032  0     0    negative - overall   \n",
       "8511  1233983941692076032  0     0    positive - overall   \n",
       "\n",
       "                                                      3  \n",
       "0     Self-driving technology + road roller! #CSCEC ...  \n",
       "1     Self-driving technology + road roller! #CSCEC ...  \n",
       "2     Self-driving technology + road roller! #CSCEC ...  \n",
       "3     Self-driving technology + road roller! #CSCEC ...  \n",
       "4     Self-driving technology + road roller! #CSCEC ...  \n",
       "...                                                 ...  \n",
       "8507  This very crafty Beijing taxi driver construct...  \n",
       "8508  This very crafty Beijing taxi driver construct...  \n",
       "8509  This very crafty Beijing taxi driver construct...  \n",
       "8510  This very crafty Beijing taxi driver construct...  \n",
       "8511  This very crafty Beijing taxi driver construct...  \n",
       "\n",
       "[8512 rows x 5 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pred_target.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv('.\\\\results\\\\covid\\\\NLI_B_EVAL\\\\test_ep_0.txt',sep=' ',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
